{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a4fe05",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e9574",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56256476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arbitragerepair import constraints, repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a889623",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('fqjo3s8eacwzxkcw.csv')\n",
    "tickers = raw_data['ticker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4cdb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exdate</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>volume</th>\n",
       "      <th>impl_volatility</th>\n",
       "      <th>option_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962943</td>\n",
       "      <td>189.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>1002.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951017</td>\n",
       "      <td>187.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939104</td>\n",
       "      <td>184.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>1007.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.927205</td>\n",
       "      <td>182.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>C</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.915319</td>\n",
       "      <td>179.975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     exdate cp_flag  strike_price  volume  impl_volatility  \\\n",
       "0 2018-01-02 2018-01-05       C        1000.0       0         0.962943   \n",
       "1 2018-01-02 2018-01-05       C        1002.5       0         0.951017   \n",
       "2 2018-01-02 2018-01-05       C        1005.0       0         0.939104   \n",
       "3 2018-01-02 2018-01-05       C        1007.5       0         0.927205   \n",
       "4 2018-01-02 2018-01-05       C        1010.0       0         0.915319   \n",
       "\n",
       "   option_price  \n",
       "0       189.975  \n",
       "1       187.475  \n",
       "2       184.975  \n",
       "3       182.475  \n",
       "4       179.975  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a711ce36",
   "metadata": {},
   "source": [
    "## Revise stock prices\n",
    "\n",
    "### Upload stock data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "410fbc30-ef04-442d-b112-9f8f950303c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ./data/adjusted_Stock_Daily/amzn_stock_daily_adjusted.csv\n",
      "saved to ./data/adjusted_Stock_Daily/jpm_stock_daily_adjusted.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ./data/adjusted_Stock_Daily/jnj_stock_daily_adjusted.csv\n",
      "saved to ./data/adjusted_Stock_Daily/msft_stock_daily_adjusted.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ./data/adjusted_Stock_Daily/pg_stock_daily_adjusted.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ./data/adjusted_Stock_Daily/wmt_stock_daily_adjusted.csv\n",
      "saved to ./data/adjusted_Stock_Daily/googl_stock_daily_adjusted.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to ./data/adjusted_Stock_Daily/v_stock_daily_adjusted.csv\n",
      "saved to ./data/adjusted_Stock_Daily/tsla_stock_daily_adjusted.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "\n",
    "## download split history\n",
    "splits_data = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    splits = stock.splits\n",
    "    splits.name = ticker  \n",
    "    splits_data = splits_data.join(splits, how='outer')  \n",
    "splits_data = splits_data[splits_data.index >= '2018-01-01']\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    \n",
    "    stock = yf.Ticker(ticker)\n",
    "    start_date = dt.datetime(2018, 1, 1)\n",
    "    tickers_list = [ticker]\n",
    "    df_stock = yf.download(tickers_list, start=start_date, progress=True)\n",
    "    \n",
    "    df_stock.reset_index(inplace=True)\n",
    "    df_stock['date'] = pd.to_datetime(df_stock['Date'], format=\"%d/%m/%y\")\n",
    "    df_stock = df_stock[['date','Adj Close']].copy()\n",
    "    df_stock.rename(columns = {'Adj Close' : 'adjusted_price'}, inplace = True)\n",
    "\n",
    "    split_stock = splits_data[ticker].dropna()\n",
    "    if len(split_stock) != 0:\n",
    "        for date in split_stock.index:\n",
    "            mask = df_stock['date'] < date.tz_localize(None)\n",
    "            df_stock.loc[mask, 'adjusted_price'] *= split_stock.loc[date]\n",
    "\n",
    "    fn = './data/adjusted_Stock_Daily/{}_stock_daily_adjusted.csv'.format(ticker.lower())\n",
    "    df_stock.to_csv(fn, sep=',', encoding='utf-8')\n",
    "    print('saved to %s'%(fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0e5e1",
   "metadata": {},
   "source": [
    "### Process different pairs of data, with 3 months difference for T2 and T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59e3901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbitrage repair function\n",
    "# pip install pandas_market_calendars\n",
    "import pandas_market_calendars as mcal\n",
    "def arbitrageRepair(columnT, columnK, columnC, columnF):\n",
    "    # normalise strikes and call prices\n",
    "    normaliser = constraints.Normalise()\n",
    "    T = np.array(columnT)\n",
    "    K = np.array(columnK)\n",
    "    C = np.array(columnC)\n",
    "    F = np.array(columnF)\n",
    "    normaliser.fit(T, K, C, F)\n",
    "    T1, K1, C1 = normaliser.transform(T, K, C)\n",
    "    \n",
    "    # construct arbitrage constraints and detect violation\n",
    "    mat_A, vec_b, _, _ = constraints.detect(T1, K1, C1, verbose=False)\n",
    "    \n",
    "    # repair arbitrage - l1-norm objective\n",
    "    epsilon = repair.l1(mat_A, vec_b, C1)\n",
    "    \n",
    "    # de-normalise\n",
    "    K0, C0 = normaliser.inverse_transform(K1, C1 + epsilon)\n",
    "    \n",
    "    return K0, C0\n",
    "\n",
    "\n",
    "def dataProcess2Di(df,t1,t2,ticker,stock_daily):\n",
    "\n",
    "    # call options data\n",
    "    df_t1_C = df.loc[(df.exdate==t1)&(df.cp_flag=='C'), ['date','exdate','strike_price','volume','option_price','impl_volatility']]\n",
    "    df_t2_C = df.loc[(df.exdate==t2)&(df.cp_flag=='C'), ['date','exdate','strike_price','volume','option_price','impl_volatility']]\n",
    "\n",
    "    # put options data\n",
    "    df_t1_P = df.loc[(df.exdate==t1)&(df.cp_flag=='P'), ['date','exdate','strike_price','volume','option_price','impl_volatility']]\n",
    "    df_t2_P = df.loc[(df.exdate==t2)&(df.cp_flag=='P'), ['date','exdate','strike_price','volume','option_price','impl_volatility']]\n",
    "\n",
    "    t0List = list(df_t1_C.date.unique())\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    for t0 in t0List:\n",
    "        ## T1:\n",
    "        # t1: 20 largest trading volume\n",
    "        df_t0t1 = df_t1_C[df_t1_C.date==t0].sort_values('volume',ascending=False).iloc[0:20].drop(columns='volume').reset_index(drop=True)\n",
    "\n",
    "        # merge with put options data and stock price data\n",
    "        df_t0t1 = df_t0t1.merge(df_t1_P, on = ['date','exdate','strike_price'], suffixes = ('_C','_P'))\n",
    "        df_t0t1 = pd.merge(df_t0t1, stock_daily, on = 'date')\n",
    "\n",
    "        # calculate the forward price:\n",
    "        df_t0t1['forward_price'] = df_t0t1['adjusted_price']/((df_t0t1['adjusted_price']-(df_t0t1['option_price_C']-df_t0t1['option_price_P']))/df_t0t1['strike_price'])\n",
    "        #df_t0t1['forward_price'] = df_t0t1['adjusted_price']\n",
    "\n",
    "        # calculate the expiry:\n",
    "        # Amazon (AMZN) is listed on the NASDAQ exchange\n",
    "        amzn_t = mcal.get_calendar('NASDAQ')\n",
    "        trading_days_1 = amzn_t.valid_days(start_date=t0, end_date=t1)\n",
    "        df_t0t1['expiry'] = len(trading_days_1) / 252\n",
    "        #df_t0t1['expiry'] = (df_t0t1['exdate']-df_t0t1['date']).apply(lambda x: x.days/365)\n",
    "\n",
    "        # arbitrage repair:\n",
    "        if len(df_t0t1)==0:\n",
    "            continue\n",
    "        K0_t1, C0_t1 = arbitrageRepair(df_t0t1['expiry'], df_t0t1['strike_price'], df_t0t1['option_price_C'], df_t0t1['forward_price'])\n",
    "\n",
    "        # temporary result at t0:\n",
    "        result_t1 = df_t0t1[['date','exdate']].copy()\n",
    "        result_t1['strike_price'] = K0_t1\n",
    "        result_t1['call_option_price'] = C0_t1\n",
    "\n",
    "\n",
    "        ## T2:\n",
    "        # t2: 20 largest trading volume\n",
    "        df_t0t2 = df_t2_C[df_t2_C.date==t0].sort_values('volume',ascending=False).iloc[0:20].drop(columns='volume').reset_index(drop=True)\n",
    "\n",
    "        # merge with put options data and stock price data\n",
    "        df_t0t2 = pd.merge(df_t0t2, df_t2_P, on = ['date','exdate','strike_price'], suffixes = ('_C','_P'))\n",
    "        df_t0t2 = pd.merge(df_t0t2, stock_daily, on = 'date')\n",
    "\n",
    "        # calculate the forward price:\n",
    "        df_t0t2['forward_price'] = df_t0t2['adjusted_price']/((df_t0t2['adjusted_price']-(df_t0t2['option_price_C']-df_t0t2['option_price_P']))/df_t0t2['strike_price'])\n",
    "        # df_t0t2['forward_price'] = df_t0t2['adjusted_price']\n",
    "\n",
    "        # calculate the expiry:\n",
    "        trading_days_2 = amzn_t.valid_days(start_date=t0, end_date=t2)\n",
    "        df_t0t2['expiry'] = len(trading_days_2) / 252\n",
    "        # df_t0t2['expiry'] = (df_t0t2['exdate']-df_t0t2['date']).apply(lambda x: x.days/365)\n",
    "\n",
    "        # arbitrage repair:\n",
    "        if len(df_t0t2)==0:\n",
    "            continue\n",
    "        K0_t2, C0_t2 = arbitrageRepair(df_t0t2['expiry'], df_t0t2['strike_price'], df_t0t2['option_price_C'], df_t0t2['forward_price'])\n",
    "\n",
    "        # temporary result at t0:\n",
    "        result_t2 = df_t0t2[['date','exdate']].copy()\n",
    "        result_t2['strike_price'] = K0_t2\n",
    "        result_t2['call_option_price'] = C0_t2\n",
    "\n",
    "\n",
    "        ## Concat horizontally  \n",
    "        result_tmp = pd.concat([result_t1, result_t2.drop(columns='date')], axis=1)\n",
    "\n",
    "        ## Concat vertically\n",
    "        result = pd.concat([result,result_tmp], axis=0)\n",
    "\n",
    "    result.columns = ['date', 'T1', 'K1', 'C1',  'T2', 'K2', 'C2']\n",
    "    result = result.reset_index(drop=True)\n",
    "    result = pd.merge(result, stock_daily, on = 'date')\n",
    "#     import pdb\n",
    "#     pdb.set_trace()\n",
    "    result.columns = ['t0', 'T1', 'K1', 'C1',  'T2', 'K2', 'C2',  'Adj_S0']\n",
    "    file_name = 'data/paired_Option/{}_{}_{}.csv'.format(ticker,pd.to_datetime(t1).strftime('%Y%m%d'),pd.to_datetime(t2).strftime('%Y%m%d'))\n",
    "    result.to_csv(file_name, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60b7949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "for ticker in tickers:\n",
    "    stock_Daily = pd.read_csv('data/adjusted_Stock_Daily/{}_stock_daily_adjusted.csv'.format(ticker.lower()),index_col=0)\n",
    "    stock_Daily['date'] = pd.to_datetime(stock_Daily['date'])\n",
    "    df = raw_data.loc[raw_data.ticker==ticker, \n",
    "                      ['date','exdate','cp_flag','strike_price','best_bid','best_offer','volume','impl_volatility']].copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['exdate'] = pd.to_datetime(df['exdate'])\n",
    "    df['strike_price'] = df['strike_price']/1000 # scaling strike\n",
    "    df['option_price'] = df[['best_bid','best_offer']].mean(axis=1)\n",
    "    df = df.drop(columns = ['best_bid','best_offer'])\n",
    "    df.head()\n",
    "\n",
    "    ## Select T1 and T2 which has closest difference of 3 months, arbitrage repair and save to path 'data/'\n",
    "    T1_List = df['exdate'].unique()\n",
    "    T1_T2_List = pd.DataFrame()\n",
    "    for t1 in T1_List:\n",
    "        t2 = T1_List[T1_List.year*12+T1_List.month == t1.year*12+t1.month+1]\n",
    "        if len(t2) > 1:\n",
    "            t2 = t2[t2.day == min(np.abs(t2.day-t1.day))]\n",
    "        if len(t2) > 0:\n",
    "            T1_T2_List = pd.concat([T1_T2_List,pd.DataFrame([t1,t2[0]]).T])\n",
    "    for t2 in T1_T2_List[1]:\n",
    "        if len(T1_T2_List[T1_T2_List[1]==t2]) >1:\n",
    "            df_t2 = T1_T2_List[T1_T2_List[1]==t2]\n",
    "            df_t2['diff'] = np.abs(df_t2[0].dt.day - t2.day)\n",
    "            df_t2 = df_t2.sort_values(by='diff').iloc[:1,:2]\n",
    "            T1_T2_List = pd.concat([T1_T2_List[T1_T2_List[1]!=t2],df_t2])\n",
    "\n",
    "    for i in range(len(T1_T2_List)):\n",
    "        t1 = T1_T2_List.iloc[i,0]\n",
    "        t2 = T1_T2_List.iloc[i,1]\n",
    "        dataProcess2Di(df,t1,t2,ticker=ticker,stock_daily=stock_Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7056947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
